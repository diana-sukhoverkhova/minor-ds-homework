{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hse-at-hw-3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExuV3ktSQYrH"
      },
      "source": [
        "# Введение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef6180WvQbD-"
      },
      "source": [
        "В этом задании Вы продолжите работать с данными из семинара [Articles Sharing and Reading from CI&T Deskdrop](https://www.kaggle.com/gspmoreira/articles-sharing-reading-from-cit-deskdrop)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5mH3ZolSlcm"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import scipy.sparse as sp\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSV_mxD9TciM"
      },
      "source": [
        "## Загрузка и предобработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRQVuRvER0hd"
      },
      "source": [
        "Загрузим данные и проведем предобраотку данных как на семинаре."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E837g9kQTbb"
      },
      "source": [
        "!wget -q -N https://www.dropbox.com/s/z8syrl5trawxs0n/articles.zip?dl=0 -O articles.zip\n",
        "!unzip -o -q articles.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "hdM1xSchR9jt",
        "outputId": "ae488d7c-6b21-40ec-ed95-eeb8c3bcab6b"
      },
      "source": [
        "articles_df = pd.read_csv('articles/shared_articles.csv')\n",
        "articles_df = articles_df[articles_df['eventType'] == 'CONTENT SHARED']\n",
        "articles_df.head(2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>eventType</th>\n",
              "      <th>contentId</th>\n",
              "      <th>authorPersonId</th>\n",
              "      <th>authorSessionId</th>\n",
              "      <th>authorUserAgent</th>\n",
              "      <th>authorRegion</th>\n",
              "      <th>authorCountry</th>\n",
              "      <th>contentType</th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1459193988</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>-4110354420726924665</td>\n",
              "      <td>4340306774493623681</td>\n",
              "      <td>8940341205206233829</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>http://www.nytimes.com/2016/03/28/business/dea...</td>\n",
              "      <td>Ethereum, a Virtual Currency, Enables Transact...</td>\n",
              "      <td>All of this work is still very early. The firs...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1459194146</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>-7292285110016212249</td>\n",
              "      <td>4340306774493623681</td>\n",
              "      <td>8940341205206233829</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>http://cointelegraph.com/news/bitcoin-future-w...</td>\n",
              "      <td>Bitcoin Future: When GBPcoin of Branson Wins O...</td>\n",
              "      <td>The alarm clock wakes me at 8:00 with stream o...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    timestamp  ... lang\n",
              "1  1459193988  ...   en\n",
              "2  1459194146  ...   en\n",
              "\n",
              "[2 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "KK9wMAkvSjbk",
        "outputId": "359da6bf-62be-4eab-ca85-74bde0227804"
      },
      "source": [
        "interactions_df = pd.read_csv('articles/users_interactions.csv')\n",
        "interactions_df.head(2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>eventType</th>\n",
              "      <th>contentId</th>\n",
              "      <th>personId</th>\n",
              "      <th>sessionId</th>\n",
              "      <th>userAgent</th>\n",
              "      <th>userRegion</th>\n",
              "      <th>userCountry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1465413032</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>-3499919498720038879</td>\n",
              "      <td>-8845298781299428018</td>\n",
              "      <td>1264196770339959068</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1465412560</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>8890720798209849691</td>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>3621737643587579081</td>\n",
              "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...</td>\n",
              "      <td>NY</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    timestamp eventType  ...  userRegion  userCountry\n",
              "0  1465413032      VIEW  ...         NaN          NaN\n",
              "1  1465412560      VIEW  ...          NY           US\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nQScdSTTzNG"
      },
      "source": [
        "interactions_df.personId = interactions_df.personId.astype(str)\n",
        "interactions_df.contentId = interactions_df.contentId.astype(str)\n",
        "articles_df.contentId = articles_df.contentId.astype(str)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu6R9rDQT2P4"
      },
      "source": [
        "# зададим словарь определяющий силу взаимодействия\n",
        "event_type_strength = {\n",
        "   'VIEW': 1.0,\n",
        "   'LIKE': 2.0, \n",
        "   'BOOKMARK': 2.5, \n",
        "   'FOLLOW': 3.0,\n",
        "   'COMMENT CREATED': 4.0,  \n",
        "}\n",
        "\n",
        "interactions_df['eventStrength'] = interactions_df.eventType.apply(lambda x: event_type_strength[x])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATO5PRRwUkQ0"
      },
      "source": [
        "Оставляем только тех пользователей, которые произамодействовали более чем с пятью статьями."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-0HoboYUBm5",
        "outputId": "45699055-e42c-4d8c-bc05-ae6917b84aaa"
      },
      "source": [
        "users_interactions_count_df = (\n",
        "    interactions_df\n",
        "    .groupby(['personId', 'contentId'])\n",
        "    .first()\n",
        "    .reset_index()\n",
        "    .groupby('personId').size())\n",
        "print('# users:', len(users_interactions_count_df))\n",
        "\n",
        "users_with_enough_interactions_df = \\\n",
        "    users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['personId']]\n",
        "print('# users with at least 5 interactions:', len(users_with_enough_interactions_df))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# users: 1895\n",
            "# users with at least 5 interactions: 1140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQagI3DHUuX5"
      },
      "source": [
        "Оставляем только те взаимодействия, которые относятся к отфильтрованным пользователям."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34rrdGdpUFgk"
      },
      "source": [
        "interactions_from_selected_users_df = interactions_df.loc[np.in1d(interactions_df.personId,\n",
        "            users_with_enough_interactions_df)]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd3VS_BgU9HN",
        "outputId": "6010493f-23c4-451a-f050-95078a206cd9"
      },
      "source": [
        "print('# interactions before:', interactions_df.shape)\n",
        "print('# interactions after:', interactions_from_selected_users_df.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# interactions before: (72312, 9)\n",
            "# interactions after: (69868, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYpRiFkQVR6B"
      },
      "source": [
        "Объединяем все взаимодействия пользователя по каждой статье и сглажиываем полученный результат, взяв от него логарифм."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mtPtAehKVEUu",
        "outputId": "11b65a27-df6b-4012-a90c-59f293d71c83"
      },
      "source": [
        "def smooth_user_preference(x):\n",
        "    return math.log(1+x, 2)\n",
        "    \n",
        "interactions_full_df = (\n",
        "    interactions_from_selected_users_df\n",
        "    .groupby(['personId', 'contentId']).eventStrength.sum()\n",
        "    .apply(smooth_user_preference)\n",
        "    .reset_index().set_index(['personId', 'contentId'])\n",
        ")\n",
        "interactions_full_df['last_timestamp'] = (\n",
        "    interactions_from_selected_users_df\n",
        "    .groupby(['personId', 'contentId'])['timestamp'].last()\n",
        ")\n",
        "        \n",
        "interactions_full_df = interactions_full_df.reset_index()\n",
        "interactions_full_df.head(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personId</th>\n",
              "      <th>contentId</th>\n",
              "      <th>eventStrength</th>\n",
              "      <th>last_timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>-5065077552540450930</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1470395911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>-6623581327558800021</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1487240080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>-793729620925729327</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1472834892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>1469580151036142903</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1487240062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>7270966256391553686</td>\n",
              "      <td>1.584963</td>\n",
              "      <td>1485994324</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               personId             contentId  eventStrength  last_timestamp\n",
              "0  -1007001694607905623  -5065077552540450930       1.000000      1470395911\n",
              "1  -1007001694607905623  -6623581327558800021       1.000000      1487240080\n",
              "2  -1007001694607905623   -793729620925729327       1.000000      1472834892\n",
              "3  -1007001694607905623   1469580151036142903       1.000000      1487240062\n",
              "4  -1007001694607905623   7270966256391553686       1.584963      1485994324"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODJYMtnNWM5w"
      },
      "source": [
        "Разобьём выборку на обучение и контроль по времени."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "3F2CfAwoVrfo",
        "outputId": "ec71667a-83e2-4d6c-8f70-92bba7bc9398"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "split_ts = 1475519530\n",
        "interactions_train_df = interactions_full_df.loc[interactions_full_df.last_timestamp < split_ts].copy()\n",
        "interactions_test_df = interactions_full_df.loc[interactions_full_df.last_timestamp >= split_ts].copy()\n",
        "\n",
        "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
        "print('# interactions on Test set: %d' % len(interactions_test_df))\n",
        "\n",
        "interactions_train_df"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# interactions on Train set: 29329\n",
            "# interactions on Test set: 9777\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personId</th>\n",
              "      <th>contentId</th>\n",
              "      <th>eventStrength</th>\n",
              "      <th>last_timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>-5065077552540450930</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1470395911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>-793729620925729327</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1472834892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>-1006791494035379303</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1469129122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>-1039912738963181810</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1459376415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>-1081723567492738167</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1464054093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39099</th>\n",
              "      <td>997469202936578234</td>\n",
              "      <td>9112765177685685246</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1472479493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39100</th>\n",
              "      <td>998688566268269815</td>\n",
              "      <td>-1255189867397298842</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1474567164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39101</th>\n",
              "      <td>998688566268269815</td>\n",
              "      <td>-401664538366009049</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1474567449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39103</th>\n",
              "      <td>998688566268269815</td>\n",
              "      <td>6881796783400625893</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1474567675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39105</th>\n",
              "      <td>998688566268269815</td>\n",
              "      <td>739747367187387064</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1474567514</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29329 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   personId  ... last_timestamp\n",
              "0      -1007001694607905623  ...     1470395911\n",
              "2      -1007001694607905623  ...     1472834892\n",
              "6      -1032019229384696495  ...     1469129122\n",
              "7      -1032019229384696495  ...     1459376415\n",
              "8      -1032019229384696495  ...     1464054093\n",
              "...                     ...  ...            ...\n",
              "39099    997469202936578234  ...     1472479493\n",
              "39100    998688566268269815  ...     1474567164\n",
              "39101    998688566268269815  ...     1474567449\n",
              "39103    998688566268269815  ...     1474567675\n",
              "39105    998688566268269815  ...     1474567514\n",
              "\n",
              "[29329 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5G3FTYOXLVg"
      },
      "source": [
        "Для удобства подсчёта качества запишем данные в формате, где строка соответствует пользователю, а столбцы будут истинными метками и предсказаниями в виде списков."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "RT-_toqfXOa2",
        "outputId": "2a988500-6905-4314-a4fd-5b72a3da0ff3"
      },
      "source": [
        "interactions = (\n",
        "    interactions_train_df\n",
        "    .groupby('personId')['contentId'].agg(lambda x: list(x))\n",
        "    .reset_index()\n",
        "    .rename(columns={'contentId': 'true_train'})\n",
        "    .set_index('personId')\n",
        ")\n",
        "\n",
        "interactions['true_test'] = (\n",
        "    interactions_test_df\n",
        "    .groupby('personId')['contentId'].agg(lambda x: list(x))\n",
        ")\n",
        "\n",
        "# заполнение пропусков пустыми списками\n",
        "interactions.loc[pd.isnull(interactions.true_test), 'true_test'] = [\n",
        "    list() for x in range(len(interactions.loc[pd.isnull(interactions.true_test), 'true_test']))]\n",
        "\n",
        "interactions.head(1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>true_train</th>\n",
              "      <th>true_test</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>personId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-1007001694607905623</th>\n",
              "      <td>[-5065077552540450930, -793729620925729327]</td>\n",
              "      <td>[-6623581327558800021, 1469580151036142903, 72...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       true_train                                          true_test\n",
              "personId                                                                                                            \n",
              "-1007001694607905623  [-5065077552540450930, -793729620925729327]  [-6623581327558800021, 1469580151036142903, 72..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UWDyWKsamSa"
      },
      "source": [
        "## Библиотека LightFM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-iXjvdZa25Z"
      },
      "source": [
        "Для рекомендации Вы будете пользоваться библиотекой [LightFM](https://making.lyst.com/lightfm/docs/home.html), в которой реализованы популярные алгоритмы. Для оценивания качества рекомендации, как и на семинаре, будем пользоваться метрикой *precision@10*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qtyn38PZXPLf",
        "outputId": "56141a1a-2d31-432b-9b61-0b5dfc717133"
      },
      "source": [
        "!pip install lightfm\n",
        "from lightfm import LightFM\n",
        "from lightfm.evaluation import precision_at_k"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lightfm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/fe/8864d723daa8e5afc74080ce510c30f7ad52facf6a157d4b42dec83dfab4/lightfm-1.16.tar.gz (310kB)\n",
            "\r\u001b[K     |█                               | 10kB 21.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 28.2MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 22.1MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 112kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 133kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 153kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 204kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 215kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 225kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 235kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 245kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 256kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 266kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 276kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 286kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 296kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 307kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lightfm) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightfm) (0.22.2.post1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (1.0.1)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.16-cp37-cp37m-linux_x86_64.whl size=705351 sha256=818ea5f1af57560393473e7c8ef70033f2986f47d83405fc87c60f66384d6281\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/64/d4/673c7277f71ac4c5ad4835b94708c01b653ef2d3aa78ef20aa\n",
            "Successfully built lightfm\n",
            "Installing collected packages: lightfm\n",
            "Successfully installed lightfm-1.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CjyGqulcZTf"
      },
      "source": [
        "## Задание 1. (2 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Sof6V5Dd4h9"
      },
      "source": [
        "Модели в LightFM работают с разреженными матрицами. Создайте разреженные матрицы `data_train` и `data_test` (размером количество пользователей на количество статей), такие что на пересечении строки пользователя и столбца статьи стоит сила их взаимодействия, если взаимодействие было, и стоит ноль, если взаимодействия не было."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn5HnE1gKAHi"
      },
      "source": [
        "# Ваш код здесь\n",
        "\n",
        "# используем класс Dataset для модели LightFM\n",
        "from lightfm.data import Dataset\n",
        "\n",
        "data = Dataset()\n",
        "data.fit(interactions_full_df.personId.unique(), interactions_full_df.contentId.unique())\n",
        "data_train, weights_matrix_train = data.build_interactions([tuple(i) for i in interactions_train_df.drop(['eventStrength', 'last_timestamp'], axis = 1).values])\n",
        "data_test, weights_matrix_test = data.build_interactions([tuple(i) for i in interactions_test_df.drop(['eventStrength', 'last_timestamp'], axis = 1).values])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiNGVzTveRXE"
      },
      "source": [
        "## Задание 2. (1 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPfVK3STeryM"
      },
      "source": [
        "Обучите модель LightFM с `loss='warp'` и посчитайте *precision@10* на тесте."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFQxeHw8eVLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bdd38a6-c3be-4b94-b3d4-79f930b130bf"
      },
      "source": [
        "# Ваш код здесь\n",
        "\n",
        "# сразу зафиксируем random_state для получения одинаковых результатов при повторном обучении модели\n",
        "model = LightFM(loss='warp', random_state=7)\n",
        "model.fit(data_train, sample_weight = weights_matrix_train)\n",
        "precision = precision_at_k(model, data_test, data_train, k=10).mean()\n",
        "\n",
        "print('Precision@10:', precision)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision@10: 0.004480651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZDsG1iAfdrl"
      },
      "source": [
        "## Задание 3. (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F93chvtbgA9N"
      },
      "source": [
        "При вызове метода `fit` LightFM позволяет передавать в `item_features` признаковое описание объектов. Воспользуемся этим. Будем получать признаковое описание из текста статьи в виде [TF-IDF](https://ru.wikipedia.org/wiki/TF-IDF) (можно воспользоваться `TfidfVectorizer` из scikit-learn). Создайте матрицу `feat` размером количество статей на размер признакового описание и обучите LightFM с `loss='warp'` и посчитайте precision@10 на тесте."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f__BJOnO38lG",
        "outputId": "f5c3d050-dc7c-4635-e0b7-aaa1c59176d5"
      },
      "source": [
        "# Ваш код здесь\n",
        "\n",
        "# получим список всех текстов статей (всего 3047)\n",
        "corpus = list(articles_df.text)\n",
        "len(corpus)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3047"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SvUi_Fofgf5"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=300)\n",
        "feat = vectorizer.fit_transform(corpus)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaSN1-Rz5BbS",
        "outputId": "ed6a79eb-3dac-4751-ff58-cfc93781ecd0"
      },
      "source": [
        "feat.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3047, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA6Sodli2ksA",
        "outputId": "de97843a-ee6d-416f-a1a1-6f054d3fee6c"
      },
      "source": [
        "model = LightFM(loss='warp', random_state=7)\n",
        "model.fit(data_train, sample_weight = weights_matrix_train, item_features=feat)\n",
        "precision = precision_at_k(model, data_test, data_train, item_features=feat, k=10).mean()\n",
        "\n",
        "print('Precision@10:', precision)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision@10: 0.010794298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWq2dEIvIzv1"
      },
      "source": [
        "__Подбор гиперпараметра max_features:__ \\\\\n",
        "\n",
        "max_features = 1000 - precision ~ 0.002 \\\\\n",
        "max_features = 500 --- precision ~ 0.003 \\\\\n",
        "max_features = 400 --- precision ~ 0.001 \\\\\n",
        "max_features = 300 --- precision ~ 0.01 \\\\\n",
        "max_features = 200 --- precision ~ 0.002 \\\\\n",
        "Поэтому оставляем max_features = 300\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lwuex6PpsFw"
      },
      "source": [
        "## Задание 4. (2 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aZcHjSzp2cZ"
      },
      "source": [
        "В задании 3 мы использовали сырой текст статей. В этом задании необходимо сначала сделать предобработку текста (привести к нижнему регистру, убрать стоп слова, привести слова к нормальной форме и т.д.), после чего обучите модель и оценить качество на тестовых данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88OcD-96Ow7g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57963e97-bd92-4dc1-caf9-6d55260f1b37"
      },
      "source": [
        "# Ваш код здесь\n",
        "\n",
        "# найдем языки, встречающиеся в текстах статей, чтобы добавить стоп-слова из разных языков\n",
        "!pip install langdetect"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/72/a3add0e4eec4eb9e2569554f7c70f4a3c27712f40e3284d483e88094cc0e/langdetect-1.0.9.tar.gz (981kB)\n",
            "\r\u001b[K     |▍                               | 10kB 15.2MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 21.1MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 21.1MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40kB 17.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51kB 9.1MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 9.2MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71kB 9.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81kB 10.4MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 10.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 102kB 8.7MB/s eta 0:00:01\r\u001b[K     |███▊                            | 112kB 8.7MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 8.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 133kB 8.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 143kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 163kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 174kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 194kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 204kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 225kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 235kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 256kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 266kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 286kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 296kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 317kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 327kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 348kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 358kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 378kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 389kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 409kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 419kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 440kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 450kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 471kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 481kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 501kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 512kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 532kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 542kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 563kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 573kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 593kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 604kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 624kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 634kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 655kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 665kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 686kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 696kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 716kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 727kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 747kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 757kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 768kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 778kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 788kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 798kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 808kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 819kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 829kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 839kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 849kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 860kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 870kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 880kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 890kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 901kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 911kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 921kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 931kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 942kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 952kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 962kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 972kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 983kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-cp37-none-any.whl size=993223 sha256=0578ff05848dcd721eed5fe698e6106feb257b1f2df539fcfaaf51ac2e23ab6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/18/13/038c34057808931c7ddc6c92d3aa015cf1a498df5a70268996\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foSvzuUnNxT-",
        "outputId": "76650904-5299-446a-b0a7-2675500a3aaa"
      },
      "source": [
        "from langdetect import detect\n",
        "\n",
        "lang = set([detect(text) for text in corpus])\n",
        "lang"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ca', 'en', 'es', 'pt'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94aDNNSmPbB6"
      },
      "source": [
        "# тексты статей: catalan, english, spanish, portugues"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaWeZ_j6KV7X",
        "outputId": "84c55dd4-48c0-4671-c4a1-3f77d3d39423"
      },
      "source": [
        "# предобработка текста\n",
        "\n",
        "import string\n",
        "import torchtext\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "# добавим лемматизацию слов\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "# уберем частые слова\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def digit(s): # функция проверки на наличие цифр в строке \n",
        "    return all([c.isdigit() for c in s])\n",
        "\n",
        "# в пакете stopwords нет языка 'catalan', поэтому слова этого языка не добавляем в список стоп-слов\n",
        "stop_words = set(stopwords.words('english')) \\\n",
        "                .union(set(stopwords.words('spanish'))) \\\n",
        "                .union(set(stopwords.words('portuguese')))\n",
        "\n",
        "def process_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(word) for word in word_tokenize(text.lower()) \n",
        "            if word not in stop_words \n",
        "            and (lemmatizer.lemmatize(word) not in string.punctuation)\n",
        "            and not digit(word)]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyEdpmYMz0O1"
      },
      "source": [
        "# из каждой статьи уберем частые слова, пунктуацию и числа\n",
        "process_corpus = [' '.join(process_text(text)) for text in corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sYXaYSj9dTz",
        "outputId": "ed11d030-e484-4758-f934-ef6e95d07482"
      },
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 300, ngram_range=(1, 2), min_df=0.08, sublinear_tf=True) \n",
        "feat = vectorizer.fit_transform(process_corpus)\n",
        "\n",
        "model = LightFM(loss='warp', random_state=7)\n",
        "model.fit(data_train, sample_weight = weights_matrix_train, item_features=feat)\n",
        "precision = precision_at_k(model, data_test, data_train, item_features=feat, k=10).mean()\n",
        "\n",
        "print('Precision@10:', precision)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision@10: 0.010794298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SNE7bC7-a1j"
      },
      "source": [
        "__Подбор гиперпараметров TfidfVectorizer:__\n",
        "\n",
        "TfidfVectorizer(max_features = 300, ngram_range=(1, 2), min_df=0.08) (max_df $\\in$ {0.9, 0.8, 0.7, 0.6}) --- precision = 0.0060081473  \\\\\n",
        "TfidfVectorizer(max_features = 300, ngram_range=(1, 2), min_df=0.08, sublinear_tf=True) --- precision = 0.010794298 \\\\\n",
        "TfidfVectorizer(max_features = 300, ngram_range=(1, 2), max_df=0.5, min_df=0.08) --- precision = 0.0077393074 \\\\\n",
        "TfidfVectorizer(max_features = 300, ngram_range=(1, 2), max_df=0.9, min_df=0.1) --- precision = 0.0088594705"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgayAPRpqn7L"
      },
      "source": [
        "Улучшилось ли качество предсказания? \\\\\n",
        "\n",
        "Качество почти не изменилось, но немного выросло (0.010794298 против 0.010081466)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKRzLLodq3gq"
      },
      "source": [
        "## Задание 5. (2 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brjHl49Aq8su"
      },
      "source": [
        "Подберите гиперпараметры модели LightFM (`n_components` и др.) для улучшения качества модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlwaeCiZqncD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7927b9f-c72f-4f54-87c9-58bfff53aef4"
      },
      "source": [
        "# Ваш код здесь\n",
        "for i in range(1, 21):\n",
        "  model = LightFM(loss='warp', no_components=i, random_state=7)\n",
        "  model.fit(data_train, sample_weight = weights_matrix_train, item_features=feat)\n",
        "  precision = precision_at_k(model, data_test, data_train, item_features=feat, k=10).mean()\n",
        "\n",
        "  print('Precision@10:', precision, 'no_components =', i)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision@10: 0.003869654 no_components = 1\n",
            "Precision@10: 0.0066191447 no_components = 2\n",
            "Precision@10: 0.0027494908 no_components = 3\n",
            "Precision@10: 0.009368637 no_components = 4\n",
            "Precision@10: 0.008044806 no_components = 5\n",
            "Precision@10: 0.007739308 no_components = 6\n",
            "Precision@10: 0.0061099795 no_components = 7\n",
            "Precision@10: 0.0054989816 no_components = 8\n",
            "Precision@10: 0.009368637 no_components = 9\n",
            "Precision@10: 0.010794298 no_components = 10\n",
            "Precision@10: 0.0035641547 no_components = 11\n",
            "Precision@10: 0.009164969 no_components = 12\n",
            "Precision@10: 0.00407332 no_components = 13\n",
            "Precision@10: 0.007942974 no_components = 14\n",
            "Precision@10: 0.009063137 no_components = 15\n",
            "Precision@10: 0.007535642 no_components = 16\n",
            "Precision@10: 0.005193483 no_components = 17\n",
            "Precision@10: 0.009063136 no_components = 18\n",
            "Precision@10: 0.008452139 no_components = 19\n",
            "Precision@10: 0.0018329938 no_components = 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grFeVPyA--eC",
        "outputId": "82e6a8ff-6a30-44e7-fd15-9ad042bf7f7e"
      },
      "source": [
        "model = LightFM(loss='warp', no_components=10, learning_schedule='adadelta', random_state=7)\n",
        "model.fit(data_train, sample_weight = weights_matrix_train, item_features=feat)\n",
        "precision = precision_at_k(model, data_test, data_train, item_features=feat, k=10).mean()\n",
        "\n",
        "print('Precision@10:', precision)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision@10: 0.008452138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st59eYmA_hbn",
        "outputId": "b6ab1e44-1302-41f0-a717-dfa747f60c79"
      },
      "source": [
        "for i in range(1, 21):\n",
        "  model = LightFM(loss='warp', no_components=10, item_alpha=0.01*i, random_state=7)\n",
        "  model.fit(data_train, sample_weight = weights_matrix_train, item_features=feat)\n",
        "  precision = precision_at_k(model, data_test, data_train, item_features=feat, k=10).mean()\n",
        "\n",
        "  print('Precision@10:', precision, 'item_alpha =', 0.01*i)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision@10: 0.007535642 item_alpha = 0.01\n",
            "Precision@10: 0.004378819 item_alpha = 0.02\n",
            "Precision@10: 0.005702648 item_alpha = 0.03\n",
            "Precision@10: 0.0032586558 item_alpha = 0.04\n",
            "Precision@10: 0.0029531568 item_alpha = 0.05\n",
            "Precision@10: 0.0023421592 item_alpha = 0.06\n",
            "Precision@10: 0.0038696537 item_alpha = 0.07\n",
            "Precision@10: 0.0048879837 item_alpha = 0.08\n",
            "Precision@10: 0.0041751526 item_alpha = 0.09\n",
            "Precision@10: 0.004378819 item_alpha = 0.1\n",
            "Precision@10: 0.003360489 item_alpha = 0.11\n",
            "Precision@10: 0.004480652 item_alpha = 0.12\n",
            "Precision@10: 0.004480652 item_alpha = 0.13\n",
            "Precision@10: 0.005397149 item_alpha = 0.14\n",
            "Precision@10: 0.0031568226 item_alpha = 0.15\n",
            "Precision@10: 0.003665988 item_alpha = 0.16\n",
            "Precision@10: 0.0045824847 item_alpha = 0.17\n",
            "Precision@10: 0.00407332 item_alpha = 0.18\n",
            "Precision@10: 0.0030549897 item_alpha = 0.19\n",
            "Precision@10: 0.0035641547 item_alpha = 0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-96FjH0ARSf",
        "outputId": "7ade258c-565e-4b81-a3b9-0b7066971996"
      },
      "source": [
        "for i in range(1, 21):\n",
        "  model = LightFM(loss='warp', no_components=10, user_alpha=0.01*i, random_state=7)\n",
        "  model.fit(data_train, sample_weight = weights_matrix_train, item_features=feat)\n",
        "  precision = precision_at_k(model, data_test, data_train, item_features=feat, k=10).mean()\n",
        "\n",
        "  print('Precision@10:', precision, 'user_alpha =', 0.01*i)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision@10: 0.010488799 user_alpha = 0.01\n",
            "Precision@10: 0.0105906315 user_alpha = 0.02\n",
            "Precision@10: 0.010488798 user_alpha = 0.03\n",
            "Precision@10: 0.010386966 user_alpha = 0.04\n",
            "Precision@10: 0.010794298 user_alpha = 0.05\n",
            "Precision@10: 0.011099796 user_alpha = 0.06\n",
            "Precision@10: 0.010285133 user_alpha = 0.07\n",
            "Precision@10: 0.010997963 user_alpha = 0.08\n",
            "Precision@10: 0.010794298 user_alpha = 0.09\n",
            "Precision@10: 0.010997963 user_alpha = 0.1\n",
            "Precision@10: 0.011303463 user_alpha = 0.11\n",
            "Precision@10: 0.011099796 user_alpha = 0.12\n",
            "Precision@10: 0.011099796 user_alpha = 0.13\n",
            "Precision@10: 0.011099796 user_alpha = 0.14\n",
            "Precision@10: 0.010896131 user_alpha = 0.15\n",
            "Precision@10: 0.010794298 user_alpha = 0.16\n",
            "Precision@10: 0.010183299 user_alpha = 0.17\n",
            "Precision@10: 0.010692464 user_alpha = 0.18\n",
            "Precision@10: 0.010692464 user_alpha = 0.19\n",
            "Precision@10: 0.010285133 user_alpha = 0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1iL9ipkA3_c",
        "outputId": "30a4ae92-918c-4cde-9b06-333107a3c265"
      },
      "source": [
        "for i in range(1, 21):\n",
        "  model = LightFM(loss='warp', no_components=10, user_alpha=0.11, max_sampled=i, random_state=7)\n",
        "  model.fit(data_train, sample_weight = weights_matrix_train, item_features=feat)\n",
        "  precision = precision_at_k(model, data_test, data_train, item_features=feat, k=10).mean()\n",
        "\n",
        "  print('Precision@10:', precision, 'max_sampled =', i)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision@10: 0.010896131 max_sampled = 1\n",
            "Precision@10: 0.011201629 max_sampled = 2\n",
            "Precision@10: 0.010183299 max_sampled = 3\n",
            "Precision@10: 0.010692465 max_sampled = 4\n",
            "Precision@10: 0.010896131 max_sampled = 5\n",
            "Precision@10: 0.011303463 max_sampled = 6\n",
            "Precision@10: 0.010997963 max_sampled = 7\n",
            "Precision@10: 0.011201629 max_sampled = 8\n",
            "Precision@10: 0.011303463 max_sampled = 9\n",
            "Precision@10: 0.011303463 max_sampled = 10\n",
            "Precision@10: 0.010285133 max_sampled = 11\n",
            "Precision@10: 0.011303463 max_sampled = 12\n",
            "Precision@10: 0.011405295 max_sampled = 13\n",
            "Precision@10: 0.011201629 max_sampled = 14\n",
            "Precision@10: 0.010692464 max_sampled = 15\n",
            "Precision@10: 0.011812627 max_sampled = 16\n",
            "Precision@10: 0.010896131 max_sampled = 17\n",
            "Precision@10: 0.010997963 max_sampled = 18\n",
            "Precision@10: 0.010081467 max_sampled = 19\n",
            "Precision@10: 0.011099796 max_sampled = 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptN5Bv13BYVZ",
        "outputId": "da2d0dcf-adbf-48ac-9446-165af2dcf38b"
      },
      "source": [
        "# итоговое качество \n",
        "model = LightFM(loss='warp', no_components=10, user_alpha=0.11, max_sampled=16, random_state=7)\n",
        "model.fit(data_train, sample_weight = weights_matrix_train, item_features=feat)\n",
        "precision = precision_at_k(model, data_test, data_train, item_features=feat, k=10).mean()\n",
        "\n",
        "print('Precision@10:', precision)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision@10: 0.011812627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itv_57-r5ljG"
      },
      "source": [
        "__Подбор гиперпараметров LightFM:__\n",
        "\n",
        "* no_components: \\\\\n",
        "Максимальное значение precision = 0.010794298 при значении параметра 10  \\\\\n",
        "\n",
        "* learning_schedule: \\\\\n",
        "precision = 0.008248473 при learning_schedule='adadelta' - качество понизилось, рассматриваем только learning_schedule='adagrad' \\\\\n",
        "\n",
        "* item_alpha: \\\\\n",
        "precision порядка 0.001 при изменении параметра от 0.01 до 0.2 \\\\\n",
        "\n",
        "* user_alpha: \\\\\n",
        "max_precision = 0.011303463 при user_alpha = 0.11\n",
        "\n",
        "* max_sampled: \\\\\n",
        "max_precision = 0.011812627 при max_sampled = 16 \\\\\n",
        "\n",
        "Итоговое качество: precision@10 = 0.011812627"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJA7v07NrYSF"
      },
      "source": [
        "## Бонусное задание. (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veLFUoVRrisk"
      },
      "source": [
        "Выше мы использовали достаточно простое представление текста статьи в виде TF-IDF. В этом задании Вам нужно представить текст статьи (можно вместе с заголовком) в виде эмбеддинга полученного с помощью рекуррентной сети или трансформера (можно использовать любую предобученную модель, которая Вам нравится). Обучите модель с ипользованием этих эмеддингов и сравните результаты с предыдущими."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQmn1cb-rXU3"
      },
      "source": [
        "# Ваш код здесь"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb_B5ZkMshtr"
      },
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": []
    }
  ]
}